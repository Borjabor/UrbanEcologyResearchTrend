{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21e9aaad",
   "metadata": {},
   "source": [
    "# Urban Ecology Research Trend Analysis\n",
    "\n",
    "Type: NLP + Time Series + Web Data | Domain: Scientific + environmental | Format: Notebook\n",
    "- Use PubMed or Semantic Scholar API to extract papers on 'urban ecology'.\n",
    "- Track number of publications per year.\n",
    "- Perform keyword frequency and topic modeling.\n",
    "- Map institutions or authors by location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854a13d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "BASE_URL = \"http://api.semanticscholar.org/graph/v1/paper/search/bulk\"\n",
    "FIELDS = 'title,year,authors,abstract,url,openAccessPdf'\n",
    "DELAY = 5  # delay between requests to avoid rate limiting\n",
    "RETRY_DELAY = 5  # seconds before retrying on failure\n",
    "OUTPUT_CSV = \"papers.csv\"\n",
    "OUTPUT_JSONL = \"papers.jsonl\"\n",
    "YEAR_RANGE = \"2020-\" \n",
    "\n",
    "query_list = [\n",
    "    'urban ecology',\n",
    "    'urban biodiversity',\n",
    "    'urban green spaces',\n",
    "    'urban wildlife',\n",
    "    'urban vegetation',\n",
    "    'urban environmental change',\n",
    "    'urban landscape ecology',\n",
    "    'urban ecosystem services'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4835c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this to clear the .txt progress trackers\n",
    "\n",
    "for keyword in query_list:\n",
    "    done_file = f'done_{keyword}.txt'\n",
    "    token_file = f'token_{keyword}.txt'\n",
    "    if os.path.exists(done_file):\n",
    "        os.remove(done_file)\n",
    "        print(f\"✅ Progress trackers for '{keyword}' removed.\")\n",
    "    if os.path.exists(token_file):\n",
    "        os.remove(token_file)\n",
    "        print(f\"✅ Progress trackers for '{keyword}' removed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa39136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Helper functions ===\n",
    "# keeps track of keywords and tokens to allow to keep retrieving papers from where you left off\n",
    "def save_token(keyword, token):\n",
    "    with open(f'token_{keyword}.txt', 'w') as f:\n",
    "        f.write(token)\n",
    "\n",
    "def load_token(keyword):\n",
    "    filename = f'token_{keyword}.txt'\n",
    "    if os.path.exists(filename):\n",
    "        with open(filename, 'r') as f:\n",
    "            return f.read().strip()\n",
    "    return None\n",
    "\n",
    "def mark_done(keyword):\n",
    "    with open(f'done_{keyword}.txt', 'w') as f:\n",
    "        f.write('completed')\n",
    "\n",
    "def is_done(keyword):\n",
    "    return os.path.exists(f'done_{keyword}.txt')\n",
    "\n",
    "def delete_token(keyword):\n",
    "    filename = f'token_{keyword}.txt'\n",
    "    if os.path.exists(filename):\n",
    "        os.remove(filename)\n",
    "        \n",
    "def export_jsonl_to_csv(jsonl_path, csv_path):\n",
    "    if os.path.exists(jsonl_path):\n",
    "        with open(jsonl_path, 'r', encoding='utf-8') as f:\n",
    "            papers = [json.loads(line) for line in f]\n",
    "\n",
    "        df = pd.json_normalize(papers)\n",
    "\n",
    "        if \"paperId\" in df.columns:\n",
    "            df = df.drop_duplicates(subset=\"paperId\")\n",
    "            print(f\"📌 Deduplicated. Final count: {len(df)} unique papers.\")\n",
    "        else:\n",
    "            print(\"⚠️ Warning: No 'paperId' field found to deduplicate.\")\n",
    "\n",
    "        df.to_csv(csv_path, index=False)\n",
    "        print(f\"📁 Saved to {csv_path}\")\n",
    "    else:\n",
    "        print(\"⚠️ No data found. Make sure the JSONL file exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efc42f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Searching for: 'urban ecology'\n",
      "📄 Retrieved 1000 papers so far for 'urban ecology'\n",
      "📄 Retrieved 2000 papers so far for 'urban ecology'\n",
      "📄 Retrieved 3000 papers so far for 'urban ecology'\n",
      "📄 Retrieved 4000 papers so far for 'urban ecology'\n",
      "📄 Retrieved 4772 papers so far for 'urban ecology'\n",
      "📄 Retrieved 5772 papers so far for 'urban ecology'\n",
      "📄 Retrieved 6772 papers so far for 'urban ecology'\n",
      "📄 Retrieved 7772 papers so far for 'urban ecology'\n",
      "📄 Retrieved 8772 papers so far for 'urban ecology'\n",
      "📄 Retrieved 9544 papers so far for 'urban ecology'\n",
      "📄 Retrieved 10544 papers so far for 'urban ecology'\n",
      "📄 Retrieved 11544 papers so far for 'urban ecology'\n",
      "📄 Retrieved 12544 papers so far for 'urban ecology'\n",
      "📄 Retrieved 13544 papers so far for 'urban ecology'\n",
      "📄 Retrieved 14316 papers so far for 'urban ecology'\n",
      "📄 Retrieved 15316 papers so far for 'urban ecology'\n",
      "📄 Retrieved 16316 papers so far for 'urban ecology'\n",
      "📄 Retrieved 17316 papers so far for 'urban ecology'\n",
      "📄 Retrieved 18316 papers so far for 'urban ecology'\n",
      "📄 Retrieved 19088 papers so far for 'urban ecology'\n",
      "📄 Retrieved 20088 papers so far for 'urban ecology'\n",
      "📄 Retrieved 21088 papers so far for 'urban ecology'\n",
      "📄 Retrieved 22088 papers so far for 'urban ecology'\n",
      "📄 Retrieved 23088 papers so far for 'urban ecology'\n",
      "📄 Retrieved 23860 papers so far for 'urban ecology'\n",
      "📄 Retrieved 24860 papers so far for 'urban ecology'\n",
      "📄 Retrieved 25860 papers so far for 'urban ecology'\n",
      "📄 Retrieved 26860 papers so far for 'urban ecology'\n",
      "📄 Retrieved 27860 papers so far for 'urban ecology'\n",
      "📄 Retrieved 28632 papers so far for 'urban ecology'\n",
      "📄 Retrieved 29632 papers so far for 'urban ecology'\n",
      "📄 Retrieved 30632 papers so far for 'urban ecology'\n",
      "📄 Retrieved 31632 papers so far for 'urban ecology'\n",
      "📄 Retrieved 32632 papers so far for 'urban ecology'\n",
      "📄 Retrieved 33404 papers so far for 'urban ecology'\n",
      "📄 Retrieved 34404 papers so far for 'urban ecology'\n",
      "📄 Retrieved 35404 papers so far for 'urban ecology'\n",
      "📄 Retrieved 36404 papers so far for 'urban ecology'\n",
      "📄 Retrieved 37404 papers so far for 'urban ecology'\n",
      "📄 Retrieved 38176 papers so far for 'urban ecology'\n",
      "📄 Retrieved 39176 papers so far for 'urban ecology'\n",
      "📄 Retrieved 40176 papers so far for 'urban ecology'\n",
      "📄 Retrieved 41176 papers so far for 'urban ecology'\n",
      "📄 Retrieved 42176 papers so far for 'urban ecology'\n",
      "📄 Retrieved 42948 papers so far for 'urban ecology'\n",
      "📄 Retrieved 43948 papers so far for 'urban ecology'\n",
      "📄 Retrieved 44948 papers so far for 'urban ecology'\n",
      "📄 Retrieved 45948 papers so far for 'urban ecology'\n",
      "📄 Retrieved 46948 papers so far for 'urban ecology'\n",
      "📄 Retrieved 47720 papers so far for 'urban ecology'\n",
      "📄 Retrieved 48720 papers so far for 'urban ecology'\n",
      "📄 Retrieved 49720 papers so far for 'urban ecology'\n",
      "📄 Retrieved 50720 papers so far for 'urban ecology'\n",
      "📄 Retrieved 51720 papers so far for 'urban ecology'\n",
      "📄 Retrieved 52492 papers so far for 'urban ecology'\n",
      "📄 Retrieved 53492 papers so far for 'urban ecology'\n",
      "📄 Retrieved 54492 papers so far for 'urban ecology'\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 53\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m attempt \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m2\u001b[39m):\n\u001b[32m     52\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m         response = \u001b[43mrequests\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBASE_URL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     54\u001b[39m         response.raise_for_status()\n\u001b[32m     55\u001b[39m         data = response.json()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Python/UrbanEcologyResearchTrend/.venv/lib/python3.13/site-packages/requests/api.py:73\u001b[39m, in \u001b[36mget\u001b[39m\u001b[34m(url, params, **kwargs)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget\u001b[39m(url, params=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m     63\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[32m     64\u001b[39m \n\u001b[32m     65\u001b[39m \u001b[33;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     70\u001b[39m \u001b[33;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mget\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Python/UrbanEcologyResearchTrend/.venv/lib/python3.13/site-packages/requests/api.py:59\u001b[39m, in \u001b[36mrequest\u001b[39m\u001b[34m(method, url, **kwargs)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m sessions.Session() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Python/UrbanEcologyResearchTrend/.venv/lib/python3.13/site-packages/requests/sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Python/UrbanEcologyResearchTrend/.venv/lib/python3.13/site-packages/requests/sessions.py:746\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    743\u001b[39m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m    745\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n\u001b[32m--> \u001b[39m\u001b[32m746\u001b[39m     \u001b[43mr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcontent\u001b[49m\n\u001b[32m    748\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Python/UrbanEcologyResearchTrend/.venv/lib/python3.13/site-packages/requests/models.py:902\u001b[39m, in \u001b[36mResponse.content\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    900\u001b[39m         \u001b[38;5;28mself\u001b[39m._content = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    901\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m902\u001b[39m         \u001b[38;5;28mself\u001b[39m._content = \u001b[33;43mb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCONTENT_CHUNK_SIZE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mor\u001b[39;00m \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    904\u001b[39m \u001b[38;5;28mself\u001b[39m._content_consumed = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    905\u001b[39m \u001b[38;5;66;03m# don't need to release the connection; that's been handled by urllib3\u001b[39;00m\n\u001b[32m    906\u001b[39m \u001b[38;5;66;03m# since we exhausted the data.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Python/UrbanEcologyResearchTrend/.venv/lib/python3.13/site-packages/requests/models.py:820\u001b[39m, in \u001b[36mResponse.iter_content.<locals>.generate\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    818\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.raw, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    819\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m820\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m.raw.stream(chunk_size, decode_content=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    821\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    822\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Python/UrbanEcologyResearchTrend/.venv/lib/python3.13/site-packages/urllib3/response.py:1066\u001b[39m, in \u001b[36mHTTPResponse.stream\u001b[39m\u001b[34m(self, amt, decode_content)\u001b[39m\n\u001b[32m   1064\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1065\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m._fp) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._decoded_buffer) > \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1066\u001b[39m         data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m=\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1068\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m data:\n\u001b[32m   1069\u001b[39m             \u001b[38;5;28;01myield\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Python/UrbanEcologyResearchTrend/.venv/lib/python3.13/site-packages/urllib3/response.py:955\u001b[39m, in \u001b[36mHTTPResponse.read\u001b[39m\u001b[34m(self, amt, decode_content, cache_content)\u001b[39m\n\u001b[32m    952\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._decoded_buffer) >= amt:\n\u001b[32m    953\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._decoded_buffer.get(amt)\n\u001b[32m--> \u001b[39m\u001b[32m955\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raw_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    957\u001b[39m flush_decoder = amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (amt != \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data)\n\u001b[32m    959\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._decoded_buffer) == \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Python/UrbanEcologyResearchTrend/.venv/lib/python3.13/site-packages/urllib3/response.py:879\u001b[39m, in \u001b[36mHTTPResponse._raw_read\u001b[39m\u001b[34m(self, amt, read1)\u001b[39m\n\u001b[32m    876\u001b[39m fp_closed = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m._fp, \u001b[33m\"\u001b[39m\u001b[33mclosed\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    878\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._error_catcher():\n\u001b[32m--> \u001b[39m\u001b[32m879\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fp_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mread1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mread1\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fp_closed \u001b[38;5;28;01melse\u001b[39;00m \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt != \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Platform-specific: Buggy versions of Python.\u001b[39;00m\n\u001b[32m    882\u001b[39m         \u001b[38;5;66;03m# Close the connection when no data is returned\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    887\u001b[39m         \u001b[38;5;66;03m# not properly close the connection in all cases. There is\u001b[39;00m\n\u001b[32m    888\u001b[39m         \u001b[38;5;66;03m# no harm in redundantly calling close.\u001b[39;00m\n\u001b[32m    889\u001b[39m         \u001b[38;5;28mself\u001b[39m._fp.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Python/UrbanEcologyResearchTrend/.venv/lib/python3.13/site-packages/urllib3/response.py:862\u001b[39m, in \u001b[36mHTTPResponse._fp_read\u001b[39m\u001b[34m(self, amt, read1)\u001b[39m\n\u001b[32m    859\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fp.read1(amt) \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fp.read1()\n\u001b[32m    860\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    861\u001b[39m     \u001b[38;5;66;03m# StringIO doesn't like amt=None\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m862\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fp.read()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.2/Frameworks/Python.framework/Versions/3.13/lib/python3.13/http/client.py:479\u001b[39m, in \u001b[36mHTTPResponse.read\u001b[39m\u001b[34m(self, amt)\u001b[39m\n\u001b[32m    476\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.length \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt > \u001b[38;5;28mself\u001b[39m.length:\n\u001b[32m    477\u001b[39m     \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[32m    478\u001b[39m     amt = \u001b[38;5;28mself\u001b[39m.length\n\u001b[32m--> \u001b[39m\u001b[32m479\u001b[39m s = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    480\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s \u001b[38;5;129;01mand\u001b[39;00m amt:\n\u001b[32m    481\u001b[39m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[32m    482\u001b[39m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[32m    483\u001b[39m     \u001b[38;5;28mself\u001b[39m._close_conn()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.2/Frameworks/Python.framework/Versions/3.13/lib/python3.13/socket.py:719\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    717\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mcannot read from timed out object\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    718\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m719\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    720\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    721\u001b[39m     \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.2/Frameworks/Python.framework/Versions/3.13/lib/python3.13/ssl.py:1304\u001b[39m, in \u001b[36mSSLSocket.recv_into\u001b[39m\u001b[34m(self, buffer, nbytes, flags)\u001b[39m\n\u001b[32m   1300\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1301\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1302\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1303\u001b[39m           \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1304\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1305\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1306\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv_into(buffer, nbytes, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.2/Frameworks/Python.framework/Versions/3.13/lib/python3.13/ssl.py:1138\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1136\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1137\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1138\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1139\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1140\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# === Main loop over keywords ===\n",
    "\n",
    "for keyword in query_list:\n",
    "    print(f\"\\n🔍 Processing keyword: '{keyword}'\")\n",
    "\n",
    "    if is_done(keyword):\n",
    "        print(f\"✅ Keyword '{keyword}' already completed. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    token = load_token(keyword)\n",
    "    if token:\n",
    "        print(f\"🔄 Resuming from saved token for '{keyword}': {token}\")\n",
    "    else:\n",
    "        print(f\"⏳ Starting fresh for keyword '{keyword}'\")\n",
    "\n",
    "    retrieved = 0\n",
    "\n",
    "    while True:\n",
    "        params = {\n",
    "            'query': keyword,\n",
    "            'fields': FIELDS,\n",
    "            'limit': 1000,\n",
    "            'year': YEAR_RANGE\n",
    "        }\n",
    "        if token:\n",
    "            params['token'] = token\n",
    "\n",
    "        # Retry logic\n",
    "        for attempt in range(2):\n",
    "            try:\n",
    "                response = requests.get(BASE_URL, params=params, timeout=15)\n",
    "                response.raise_for_status()\n",
    "                data = response.json()\n",
    "                break\n",
    "            except requests.exceptions.RequestException as e:\n",
    "                print(f\"❌ Request error on attempt {attempt+1} for '{keyword}': {e}\")\n",
    "                if attempt == 0:\n",
    "                    print(f\"⏳ Retrying after {RETRY_DELAY} seconds...\")\n",
    "                    time.sleep(RETRY_DELAY)\n",
    "                else:\n",
    "                    print(\"⚠️ Skipping this batch due to repeated failure.\")\n",
    "                    data = None\n",
    "\n",
    "        if data is None:\n",
    "            print(f\"⚠️ No data retrieved for keyword '{keyword}', breaking loop.\")\n",
    "            break\n",
    "\n",
    "        papers = data.get('data', [])\n",
    "        if not papers:\n",
    "            print(f\"⚠️ No papers returned, assuming end of results for '{keyword}'\")\n",
    "            break\n",
    "\n",
    "        retrieved += len(papers)\n",
    "        print(f\"📄 Retrieved {retrieved} papers so far for '{keyword}'\")\n",
    "\n",
    "        with open(OUTPUT_JSONL, 'a', encoding='utf-8') as f:\n",
    "            for paper in papers:\n",
    "                json.dump(paper, f)\n",
    "                f.write('\\n')\n",
    "\n",
    "        if 'token' in data:\n",
    "            token = data['token']\n",
    "            save_token(keyword, token)\n",
    "            time.sleep(DELAY)\n",
    "        else:\n",
    "            print(f\"✅ Completed all pages for '{keyword}'\")\n",
    "            delete_token(keyword)\n",
    "            mark_done(keyword)\n",
    "            break\n",
    "\n",
    "print(\"\\n🎉 All keywords processed.\")\n",
    "\n",
    "export_jsonl_to_csv(OUTPUT_JSONL, OUTPUT_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19a045a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 5)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3167ecb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "year",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "url",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "authors",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "abstract",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "dc84ba20-540f-4a60-b0d2-9f4ce19428e1",
       "rows": [
        [
         "21",
         "A large-scale survey of the postmortem human microbiome, and its potential to provide insight into the living health condition",
         "2018.0",
         "https://www.semanticscholar.org/paper/0044b9ad0a61537a43f1688ff4052631ca3c9ad0",
         "Jennifer L. Pechal; Carl J. Schmidt; H. Jordan; M. Benbow",
         "The microbiome plays many roles in human health, often through the exclusive lens of clinical interest. The inevitable end point for all living hosts, death, has its own altered microbiome configurations. However, little is understood about the ecology and changes of microbial communities after death, or their potential utility for understanding the health condition of the recently living. Here we reveal distinct postmortem microbiomes of human hosts from a large-scale survey of death cases representing a predominantly urban population, and demonstrated these microbiomes reflected antemortem health conditions within 24–48 hours of death. Our results characterized microbial community structure and predicted function from 188 cases representing a cross-section of an industrial-urban population. We found strong niche differentiation of anatomic habitat and microbial community turnover based on topographical distribution. Microbial community stability was documented up to two days after death. Additionally, we observed a positive relationship between cell motility and time since host death. Interestingly, we discovered evidence that microbial biodiversity is a predictor of antemortem host health condition (e.g., heart disease). These findings improve the understanding of postmortem host microbiota dynamics, and provide a robust dataset to test the postmortem microbiome as a tool for assessing health conditions in living populations."
        ],
        [
         "640",
         "A large-scale survey of the postmortem human microbiome, and its potential to provide insight into the living health condition",
         "2018.0",
         "https://www.semanticscholar.org/paper/092ad2dbffdd873bfc048afd41e1004f06b26060",
         "Jennifer L. Pechal; C. Schmidt; H. Jordan; M. Benbow",
         "The microbiome plays many roles in human health, often through the exclusive lens of clinical interest. The inevitable end point for all living hosts, death, has its own altered microbiome configurations. However, little is understood about the ecology and changes of microbial communities after death, or their potential utility for understanding the health condition of the recently living. Here we reveal distinct postmortem microbiomes of human hosts from a large-scale survey of death cases representing a predominantly urban population, and demonstrated these microbiomes reflected antemortem health conditions within 24–48 hours of death. Our results characterized microbial community structure and predicted function from 188 cases representing a cross-section of an industrial-urban population. We found strong niche differentiation of anatomic habitat and microbial community turnover based on topographical distribution. Microbial community stability was documented up to two days after death. Additionally, we observed a positive relationship between cell motility and time since host death. Interestingly, we discovered evidence that microbial biodiversity is a predictor of antemortem host health condition (e.g., heart disease). These findings improve the understanding of postmortem host microbiota dynamics, and provide a robust dataset to test the postmortem microbiome as a tool for assessing health conditions in living populations."
        ],
        [
         "424",
         "Rising incidence of urban floods: understanding the causes for flood risk reduction in Kumasi, Ghana",
         "2020.0",
         "https://www.semanticscholar.org/paper/0648d90b097a3d4ef12c10f7debaeccd1c081ce1",
         "Kabila Abass",
         null
        ],
        [
         "437",
         "Rising incidence of urban floods: understanding the causes for flood risk reduction in Kumasi, Ghana",
         "2020.0",
         "https://www.semanticscholar.org/paper/0679df87e09deb01e8abbbf2da37b286729f2902",
         "Kabila Abass",
         null
        ],
        [
         "655",
         "Urban ecology",
         "2020.0",
         "https://www.semanticscholar.org/paper/096406e987ef5e11d5e14665c6ae356ac7b9fcab",
         "D. Bartmanski; I. Woodward",
         null
        ],
        [
         "851",
         "Urban ecology",
         "2020.0",
         "https://www.semanticscholar.org/paper/0c41a8ac446591a025d8f6310fa6dccd6fb3170b",
         "Patrick M. Lydon",
         null
        ],
        [
         "916",
         "Urban ecology",
         "2001.0",
         "https://www.semanticscholar.org/paper/0d06355bf700d4a9ea85a8402ea30040f32df8a1",
         "Jianguo Wu",
         null
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 7
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>url</th>\n",
       "      <th>authors</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>A large-scale survey of the postmortem human m...</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>https://www.semanticscholar.org/paper/0044b9ad...</td>\n",
       "      <td>Jennifer L. Pechal; Carl J. Schmidt; H. Jordan...</td>\n",
       "      <td>The microbiome plays many roles in human healt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640</th>\n",
       "      <td>A large-scale survey of the postmortem human m...</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>https://www.semanticscholar.org/paper/092ad2db...</td>\n",
       "      <td>Jennifer L. Pechal; C. Schmidt; H. Jordan; M. ...</td>\n",
       "      <td>The microbiome plays many roles in human healt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>Rising incidence of urban floods: understandin...</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>https://www.semanticscholar.org/paper/0648d90b...</td>\n",
       "      <td>Kabila Abass</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>Rising incidence of urban floods: understandin...</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>https://www.semanticscholar.org/paper/0679df87...</td>\n",
       "      <td>Kabila Abass</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655</th>\n",
       "      <td>Urban ecology</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>https://www.semanticscholar.org/paper/096406e9...</td>\n",
       "      <td>D. Bartmanski; I. Woodward</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>851</th>\n",
       "      <td>Urban ecology</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>https://www.semanticscholar.org/paper/0c41a8ac...</td>\n",
       "      <td>Patrick M. Lydon</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>916</th>\n",
       "      <td>Urban ecology</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>https://www.semanticscholar.org/paper/0d06355b...</td>\n",
       "      <td>Jianguo Wu</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title    year  \\\n",
       "21   A large-scale survey of the postmortem human m...  2018.0   \n",
       "640  A large-scale survey of the postmortem human m...  2018.0   \n",
       "424  Rising incidence of urban floods: understandin...  2020.0   \n",
       "437  Rising incidence of urban floods: understandin...  2020.0   \n",
       "655                                      Urban ecology  2020.0   \n",
       "851                                      Urban ecology  2020.0   \n",
       "916                                      Urban ecology  2001.0   \n",
       "\n",
       "                                                   url  \\\n",
       "21   https://www.semanticscholar.org/paper/0044b9ad...   \n",
       "640  https://www.semanticscholar.org/paper/092ad2db...   \n",
       "424  https://www.semanticscholar.org/paper/0648d90b...   \n",
       "437  https://www.semanticscholar.org/paper/0679df87...   \n",
       "655  https://www.semanticscholar.org/paper/096406e9...   \n",
       "851  https://www.semanticscholar.org/paper/0c41a8ac...   \n",
       "916  https://www.semanticscholar.org/paper/0d06355b...   \n",
       "\n",
       "                                               authors  \\\n",
       "21   Jennifer L. Pechal; Carl J. Schmidt; H. Jordan...   \n",
       "640  Jennifer L. Pechal; C. Schmidt; H. Jordan; M. ...   \n",
       "424                                       Kabila Abass   \n",
       "437                                       Kabila Abass   \n",
       "655                         D. Bartmanski; I. Woodward   \n",
       "851                                   Patrick M. Lydon   \n",
       "916                                         Jianguo Wu   \n",
       "\n",
       "                                              abstract  \n",
       "21   The microbiome plays many roles in human healt...  \n",
       "640  The microbiome plays many roles in human healt...  \n",
       "424                                               None  \n",
       "437                                               None  \n",
       "655                                               None  \n",
       "851                                               None  \n",
       "916                                               None  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers = df.title\n",
    "df[papers.isin(papers[papers.duplicated()])].sort_values('title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ffd374",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
